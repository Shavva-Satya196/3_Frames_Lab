# -*- coding: utf-8 -*-
"""3Frames.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/190CJfYmUTLQzkWXfMKxo_9Ysof16tDKw

Problem-2:
Build a word count application, where the constraints are that you have 10 MB RAM and 1
GB text file. You should be able to efficiently parse the text file and output the words and
counts in a sorted way. Write a program to read a large file, and emit the sorted words along
with the count. Try to implement fuzzy search as well (fix the spelling issues) Algorithm
should have Log N complexity.

Suppose we have to sort a 1GB file of random integers and the available ram size is 200 Mb, how will it be done?

The easiest way to do this is to use external sorting.
We divide our source file into temporary files of size equal to the size of the RAM and first sort these files.
Assume 1GB = 1024MB, so we follow following steps.

Divide the source file into 5 small temporary files each of size 200MB (i.e., equal to the size of ram).
Sort these temporary files one bye one using the ram individually (Any sorting algorithm : quick sort, merge sort).
"""

from collections import defaultdict
import heapq
import re

def split_file(file_path, chunk_size=10*1024*1024):
    with open(file_path, 'r', encoding='utf-8') as file:
        while True:
            chunk = file.read(chunk_size)
            if not chunk:
                break
            yield chunk

def count_words(chunk):
    word_counts = defaultdict(int)
    words = re.findall(r'\b\w+\b', chunk.lower())
    for word in words:
        word_counts[word] += 1
    return word_counts

def merge_counts(counts):
    merged_counts = defaultdict(int)
    for count in counts:
        for word, freq in count.items():
            merged_counts[word] += freq
    return merged_counts

def fuzzy_search(word, word_counts):
    word=word.lower()
    return [key for key in word_counts.keys() if key.startswith(word)]

def main(file_path):
    counts = []
    for chunk in split_file(file_path):
        counts.append(count_words(chunk))

    word_counts = merge_counts(counts)
    sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)

    # Output sorted words and counts
    for word, count in sorted_word_counts:
        print(f"{word}: {count}")

    # Example fuzzy search
    print("Fuzzy Search:")
    search_word = "ADD"
    suggestions = fuzzy_search(search_word, word_counts)
    print(f"Suggestions for '{search_word}': {suggestions}")

if __name__ == "__main__":
    file_path = "/content/sampcod.txt"
    main(file_path)

"""Problem-3:
Come up with an approach for product configuration, where multiple products can be
stored. Build an in-memory database or in-memory storage. We should be able to have
product categories along with product descriptions and details. We should be able to store a
wide range of types of products similar to Amazon, we should be able to implement efficient
search of the products and flexible configuration of the products. In addition to in-memory
storage, build an efficient textual search on any of the parameters (similar to search in
Amazon)."""

class Product:
    def __init__(self, name, category, description, details):
        self.name = name
        self.category = category
        self.description = description
        self.details = details

class Category:
    def __init__(self, name):
        self.name = name
        self.products = []

class ProductDatabase:
    def __init__(self):
        self.products = {}
        self.categories = {}

    def add_product(self, product):
        self.products[product.name] = product
        if product.category not in self.categories:
            self.categories[product.category] = Category(product.category)
        self.categories[product.category].products.append(product)

    def search_products(self, query):
        results = []
        for product in self.products.values():
            if query.lower() in product.name.lower() or \
               query.lower() in product.category.lower() or \
               query.lower() in product.description.lower() or \
               query.lower() in product.details.lower():
                results.append(product)
        return results

db = ProductDatabase()

# List of products
products = [
    Product("Laptop", "Electronics", "High-performance laptop", "16GB RAM, 512GB SSD"),
    Product("Smartphone", "Electronics", "Latest smartphone model", "6.7'' display, 5G connectivity"),
    Product("Headphones", "Electronics", "Noise-cancelling headphones", "Over-ear design, Bluetooth connectivity"),
    Product("Fitness Tracker", "Electronics", "Activity tracker with heart rate monitor", "Water-resistant, GPS tracking"),
    Product("Backpack", "Fashion", "Stylish backpack for everyday use", "Multiple compartments, padded straps"),
    Product("Running Shoes", "Sports", "Lightweight running shoes", "Breathable mesh, cushioned sole"),
    Product("Fitye ", "Electronics", "Activity tracker with heart rate monitor", "Water-resistant, GPS tracking")
]

# Add products to the database
for product in products:
    db.add_product(product)
# Search for products
results = db.search_products("Fit")
for product in results:
    print(f"Name: {product.name}, Category: {product.category}, Description: {product.description}")S

